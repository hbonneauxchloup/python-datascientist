{
 "cells": [
  {
   "cell_type": "raw",
   "id": "5cbe596b",
   "metadata": {},
   "source": [
    "---\n",
    "title: \"Partie 3: modéliser\"\n",
    "date: 2020-10-14T13:00:00Z\n",
    "draft: false\n",
    "weight: 35\n",
    "slug: \"modelisation\"\n",
    "icon: square-root-alt\n",
    "icon_pack: fas\n",
    "#linktitle: \"Partie 3: modéliser\"\n",
    "summary: |\n",
    "  Python est devenu incontournable grâce à ses librairies\n",
    "  de Machine Learning et de Deep Learning. Les principales\n",
    "  sont bien connues: scikit, keras, tensorflow... Cette\n",
    "  partie vise à illustrer le travail nécessaire pour\n",
    "  construire un modèle de Machine Learning ou un\n",
    "  modèle économétrique. L'exemple fil rouge de cette\n",
    "  partie est le résultat des élections présidentielles\n",
    "  US de 2020. Sans aller dans les détails des\n",
    "  algorithmes présentés, nous proposerons quelques astuces\n",
    "  pour faciliter l'entraînement de modèles où la transformation\n",
    "  d'un protype en modèle de production.\n",
    "type: book\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d220a8f",
   "metadata": {},
   "source": [
    "\n",
    "## Principes\n",
    "\n",
    "### Machine Learning ou Econométrie ?\n",
    "\n",
    "Un modèle statistique est une construction mathématique qui formalise une loi\n",
    "ayant généré les données. La différence principale entre *machine learning* (ML) et économétrie\n",
    "est dans le degré de structure imposé par le modélisateur :\n",
    "\n",
    "- En ML,\n",
    "la structure imposée par le *data scientist* est minimale et ce sont plutôt\n",
    "les algorithmes qui, sur des critères de performance statistique, vont\n",
    "déterminer une loi mathématique qui correspond aux données.\n",
    "\n",
    "- En économétrie,\n",
    "les hypothèses de structure des lois sont plus fortes (même dans un cadre semi ou non-paramétrique) et sont plus souvent imposées\n",
    "par le modélisateur.\n",
    "\n",
    "L'adoption du Machine Learning dans la littérature économique a été longue car la structuration des données est souvent le pendant empirique d'hypothèses théoriques sur le comportement des acteurs ou des marchés (Athey and Imbens, 2019).\n",
    "Ces hypothèses correspondent bien au concept de modèle statistique, coeur de l'économétrie, \n",
    "mais moins bien à l'approche algorithmique du *machine learning* \n",
    "où la loi du processus générateur des données est secondaire. \n",
    "\n",
    "Dans une conception caricaturale, et fausse, l’économétrie s’attacherait\n",
    "à comprendre la causalité de certaines variables sur une autre \n",
    "quand le *machine learning* se contenterait d'essayer de bons modèles prédictifs\n",
    "en exploitant les relations de corrélations entre les variables. \n",
    "Cette vision caricaturale est partielle car il existe des manières \n",
    "de comprendre l'influence de facteurs sur une variable d'intérêt en machine learning\n",
    "(en étudiant les *variables importance* par exemple) tout comme on peut voir \n",
    "l'économétrie comme un enjeu de prédiction, notamment lorsqu'on s'intéresse\n",
    "à des phénomènes catégoriels. \n",
    "La réelle différence est plutôt dans la démarche de recherche. \n",
    "Les économètres tendent à s'intéresser beaucoup principalement à la question de \n",
    "la distribution des effets et sa potentielle hétérogénéité \n",
    "alors que les praticiens du Machine Learning qui vont\n",
    "plutôt s'intéresser à la distribution des erreurs de prédiction.\n",
    "\n",
    "### Apprentissage supervisé ou non supervisé ?\n",
    "\n",
    "On distingue généralement deux types de méthodes, selon qu'on dispose d'information, dans l'échantillon\n",
    "d'apprentissage, sur les valeurs cibles *y* (on utilisera parfois le terme *label*) :\n",
    "\n",
    "* **apprentissage supervisé** : la valeur cible est connue et peut-être utilisée pour évaluer la qualité d'un modèle \n",
    "\n",
    "*Ex : modèles de prédiction du type régression / classification : SVM, kNN, arbres de classification...*\n",
    "\n",
    "* **apprentissage non supervisé** : la valeur cible est inconnue et ce sont des critères statistiques qui vont amener\n",
    "à sélectionner la structure de données la plus plausible. \n",
    "\n",
    "*Ex : modèles de réduction de dimension ou de clustering (PCA, kmeans...)*\n",
    "\n",
    "## Panorama d'un éco-système vaste\n",
    "\n",
    "Grâce aux principaux packages de Machine Learning (`scikit`), Deep Learning (`keras`, `pytorch`, `TensorFlow`...) et économétrie  (`statsmodels`), la modélisation est extrêmement simplifiée. Cela ne doit pas faire oublier l'importance de la structuration et de la préparation des données. Souvent, l'étape la plus cruciale est le choix du modèle le plus adapté à la structure des données.\n",
    "\n",
    "L'aide-mémoire suivante, issue de l'aide de `scikit-learn`, concernant les modèles de Machine Learning peut déjà donner de premiers enseignements sur les différentes familles de modèles:\n",
    "\n",
    "![](https://scikit-learn.org/stable/_static/ml_map.png)\n",
    "## Données\n",
    "\n",
    "### Quelques exemples de *Machine Learning* avec *open-data*\n",
    "\n",
    "Trouver un jeu de données public de qualité pour effectuer un travail\n",
    "d'apprentissage peut parfois être pénible. Il est souvent nécessaire\n",
    "de combiner plusieurs sources de données pour disposer d'un jeu de données\n",
    "approprié.\n",
    "\n",
    "`Etalab` a mis en ligne un [catalogue](https://datascience.etalab.studio/dgml/)\n",
    "des jeux de données présents sur `data.gouv` en fonction de critères de \n",
    "choix de modélisation. Il peut être utile de s'y référer de temps en temps. \n",
    "\n",
    "### Données utilisées en fil rouge de cette partie\n",
    "\n",
    "La plupart des exemples de cette partie s'appuient sur les résultats des\n",
    "élections US 2020 au niveau comtés. Plusieurs bases sont utilisées pour \n",
    "cela:\n",
    "\n",
    "* Les données électorales sont une reconstruction à partir des données du *MIT Election Lab*\n",
    "proposées sur `Github` par [@tonmcg](https://github.com/tonmcg/US_County_Level_Election_Results_08-20)\n",
    "(sur [zenodo](https://zenodo.org/record/3975765))\n",
    "ou directement disponibles sur le site du [MIT Election Lab](https://electionlab.mit.edu/data)\n",
    "* Les données socioéconomiques (population, données de revenu et de pauvreté, \n",
    "taux de chômage, variables d'éducation) proviennent de l'USDA ([source](https://www.ers.usda.gov/data-products/county-level-data-sets/))\n",
    "* Le *shapefile* vient des données du *Census Bureau*. Le fichier peut\n",
    "être téléchargé directement depuis cet url:\n",
    "<https://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_county_20m.zip>\n",
    "\n",
    "Le code pour construire une base unique à partir de ces sources diverses\n",
    "est disponible ci-dessous : "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79418dda",
   "metadata": {},
   "source": [
    "```{.python}\n",
    "import urllib\n",
    "import urllib.request\n",
    "import os\n",
    "import zipfile\n",
    "from urllib.request import Request, urlopen\n",
    "from pathlib import Path\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import geopandas as gpd\n",
    "\n",
    "def download_url(url, save_path):\n",
    "    with urllib.request.urlopen(url) as dl_file:\n",
    "        with open(save_path, 'wb') as out_file:\n",
    "            out_file.write(dl_file.read())\n",
    "\n",
    "\n",
    "def create_votes_dataframes():\n",
    "    \n",
    "  Path(\"data\").mkdir(parents=True, exist_ok=True)\n",
    "  \n",
    "  \n",
    "  download_url(\"https://www2.census.gov/geo/tiger/GENZ2019/shp/cb_2019_us_county_20m.zip\", \"data/shapefile\")\n",
    "  with zipfile.ZipFile(\"data/shapefile\", 'r') as zip_ref:\n",
    "      zip_ref.extractall(\"data/counties\")\n",
    "  \n",
    "  shp = gpd.read_file(\"data/counties/cb_2019_us_county_20m.shp\")\n",
    "  shp = shp[~shp[\"STATEFP\"].isin([\"02\", \"69\", \"66\", \"78\", \"60\", \"72\", \"15\"])]\n",
    "  shp\n",
    "  \n",
    "  df_election = pd.read_csv(\"https://raw.githubusercontent.com/tonmcg/US_County_Level_Election_Results_08-20/master/2020_US_County_Level_Presidential_Results.csv\")\n",
    "  df_election.head(2)\n",
    "  population = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/PopulationEstimates.xls?v=290.4\", header = 2).rename(columns = {\"FIPStxt\": \"FIPS\"})\n",
    "  education = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/Education.xls?v=290.4\", header = 4).rename(columns = {\"FIPS Code\": \"FIPS\", \"Area name\": \"Area_Name\"})\n",
    "  unemployment = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/Unemployment.xls?v=290.4\", header = 4).rename(columns = {\"fips_txt\": \"FIPS\", \"area_name\": \"Area_Name\", \"Stabr\": \"State\"})\n",
    "  income = pd.read_excel(\"https://www.ers.usda.gov/webdocs/DataFiles/48747/PovertyEstimates.xls?v=290.4\", header = 4).rename(columns = {\"FIPStxt\": \"FIPS\", \"Stabr\": \"State\", \"Area_name\": \"Area_Name\"})\n",
    "  \n",
    "  \n",
    "  dfs = [df.set_index(['FIPS', 'State']) for df in [population, education, unemployment, income]]\n",
    "  data_county = pd.concat(dfs, axis=1)\n",
    "  df_election = df_election.merge(data_county.reset_index(), left_on = \"county_fips\", right_on = \"FIPS\")\n",
    "  df_election['county_fips'] = df_election['county_fips'].astype(str).str.lstrip('0')\n",
    "  shp['FIPS'] = shp['GEOID'].astype(str).str.lstrip('0')\n",
    "  votes = shp.merge(df_election, left_on = \"FIPS\", right_on = \"county_fips\")\n",
    "  \n",
    "  req = Request('https://dataverse.harvard.edu/api/access/datafile/3641280?gbrecs=false')\n",
    "  req.add_header('User-Agent', 'Mozilla/5.0 (X11; Ubuntu; Linux x86_64; rv:77.0) Gecko/20100101 Firefox/77.0')\n",
    "  content = urlopen(req)\n",
    "  df_historical = pd.read_csv(content, sep = \"\\t\")\n",
    "  #df_historical = pd.read_csv('https://dataverse.harvard.edu/api/access/datafile/3641280?gbrecs=false', sep = \"\\t\")\n",
    "  \n",
    "  df_historical = df_historical.dropna(subset = [\"FIPS\"])\n",
    "  df_historical[\"FIPS\"] = df_historical[\"FIPS\"].astype(int)\n",
    "  df_historical['share'] = df_historical['candidatevotes']/df_historical['totalvotes']\n",
    "  df_historical = df_historical[[\"year\", \"FIPS\", \"party\", \"candidatevotes\", \"share\"]]\n",
    "  df_historical['party'] = df_historical['party'].fillna(\"other\")\n",
    "  \n",
    "  df_historical_wide = df_historical.pivot_table(index = \"FIPS\", values=['candidatevotes',\"share\"], columns = [\"year\",\"party\"])\n",
    "  df_historical_wide.columns = [\"_\".join(map(str, s)) for s in df_historical_wide.columns.values]\n",
    "  df_historical_wide = df_historical_wide.reset_index()\n",
    "  df_historical_wide['FIPS'] = df_historical_wide['FIPS'].astype(str).str.lstrip('0')\n",
    "  votes['FIPS'] = votes['GEOID'].astype(str).str.lstrip('0')\n",
    "  votes = votes.merge(df_historical_wide, on = \"FIPS\")\n",
    "  votes[\"winner\"] =  np.where(votes['votes_gop'] > votes['votes_dem'], 'republican', 'democrats') \n",
    "\n",
    "  return votes\n",
    "```\n",
    "\n",
    "Je l'ai également mis à disposition sur\n",
    "<a href=\"https://raw.githubusercontent.com/linogaliana/python-datascientist/master/content/course/modelisation/get_data.py\" class=\"github\"><i class=\"fab fa-github\"></i></a>\n",
    "\n",
    "## Contenu de la partie\n",
    "\n",
    "{{< list_children >}}\n",
    "\n",
    "Des éléments viendront ultérieurement enrichir cette partie, notamment\n",
    "dans le domaine économétrique : \n",
    "\n",
    "* maximum vraisemblance\n",
    "* stats bayésiennes\n",
    "* semi et non paramétrique: méthodes noyaux, GAM\n",
    "\n",
    "## Références\n",
    "\n",
    "Athey, S., & Imbens, G. W. (2019). Machine learning methods economists should know about, arxiv."
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
